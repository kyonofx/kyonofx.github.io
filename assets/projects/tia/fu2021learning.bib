@InProceedings{fu2021learning,
title = {Learning Task Informed Abstractions},
author = {Fu, Xiang and Yang, Ge and Agrawal, Pulkit and Jaakkola, Tommi},
booktitle = {Proceedings of the 38th International Conference on Machine Learning},
pages = {3480--3491},
year = {2021},
editor = {Meila, Marina and Zhang, Tong},
volume = {139},
series = {Proceedings of Machine Learning Research},
month = {18--24 Jul},
publisher = {PMLR},
pdf = {http://proceedings.mlr.press/v139/fu21b/fu21b.pdf},
url = {http://proceedings.mlr.press/v139/fu21b.html},
abstract = {Current model-based reinforcement learning methods struggle when operating from complex visual scenes due to
their inability to prioritize task-relevant features. To mitigate this problem, we propose learning Task Informed
Abstractions (TIA) that explicitly separates reward-correlated visual features from distractors. For learning TIA, we
introduce the formalism of Task Informed MDP (TiMDP) that is realized by training two models that learn visual features
via cooperative reconstruction, but one model is adversarially dissociated from the reward signal. Empirical evaluation
shows that TIA leads to significant performance gains over state-of-the-art methods on many visual control tasks where
natural and unconstrained visual distractions pose a formidable challenge. Project page: https://xiangfu.co/tia}
}